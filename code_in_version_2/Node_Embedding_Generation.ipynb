{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55a20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Neural Network Libraries\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import obonet\n",
    "\n",
    "# PhenoDP and Preprocessing\n",
    "from PhenoDP import *\n",
    "from PhenoDP_Preprocess import *\n",
    "\n",
    "# HPO Encoders\n",
    "from PSD_HPOEncoder import *\n",
    "from PCL_HPOEncoder import *\n",
    "\n",
    "# Transformers and PEFT\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# NumPy and Progress Tracking\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# HPO Ontology\n",
    "from pyhpo.ontology import Ontology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f964e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bb0f0ac5904ee997b2c9b95b0bd10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the HPO Ontology\n",
    "Ontology()\n",
    "hp_df = Ontology.to_dataframe()\n",
    "\n",
    "# Define the device for model loading\n",
    "device = \"cuda:3\"  # The device to load the model onto\n",
    "model_name_or_path = '/remote-home/share/data3/ly/phenoDP/new-checkpoint-finetune-with-4-datasets/'\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda:3\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bd4ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5605, -1.1172, -0.8311,  ...,  0.9614,  0.3591, -2.2852],\n",
      "       device='cuda:3', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "def get_average_encoding(text):\n",
    "    \"\"\"\n",
    "    Compute the average encoding of a given text using the pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to encode.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The average encoding of the text.\n",
    "    \"\"\"\n",
    "    # Convert the text into model inputs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Obtain the hidden states from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # Extract the hidden states from the last layer\n",
    "    last_hidden_states = outputs.hidden_states[-1]\n",
    "    \n",
    "    # Compute the average of the hidden states to obtain the text representation\n",
    "    average_encoding = last_hidden_states.mean(dim=1).squeeze()\n",
    "    \n",
    "    return average_encoding\n",
    "\n",
    "# Example text\n",
    "text = \"This is an example text for computing the average vector encoding.\"\n",
    "\n",
    "# Compute the average vector encoding\n",
    "average_encoding = get_average_encoding(text)\n",
    "print(average_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad11b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hpo_embedding(hpo_id, Ontology, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Retrieve the embedding for a given HPO term.\n",
    "\n",
    "    Args:\n",
    "        hpo_id (str): The ID of the HPO term.\n",
    "        Ontology: The HPO ontology object.\n",
    "        tokenizer: The tokenizer for the model.\n",
    "        model: The pre-trained model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The embedding of the HPO term, or None if not found.\n",
    "    \"\"\"\n",
    "    hpo_obj = Ontology.get_hpo_object(hpo_id)\n",
    "    if hpo_obj:\n",
    "        hpo_name = hpo_obj.name\n",
    "        # Check the cache to avoid redundant computations\n",
    "        if hpo_name in hpo_embedding_cache:\n",
    "            return hpo_embedding_cache[hpo_name]\n",
    "        else:\n",
    "            embedding = get_average_embedding([hpo_name])\n",
    "            if embedding is not None:\n",
    "                hpo_embedding_cache[hpo_name] = embedding[0]\n",
    "                return embedding[0]\n",
    "    return None\n",
    "\n",
    "def get_average_embedding(text):\n",
    "    \"\"\"\n",
    "    Compute the average embedding of a given text using the pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to encode.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The average embedding of the text.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If NaN values are detected in the embedding.\n",
    "    \"\"\"\n",
    "    # Convert the text into model inputs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Obtain the hidden states from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # Extract the hidden states from the last layer\n",
    "    last_hidden_states = outputs.hidden_states[-1]\n",
    "    \n",
    "    # Compute the average of the hidden states to obtain the text representation\n",
    "    average_encoding = last_hidden_states.mean(dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    # Check for NaN values in the embedding\n",
    "    if np.isnan(average_encoding).any():\n",
    "        raise ValueError(f\"NaN detected in embedding for text: {text}\")\n",
    "    \n",
    "    return average_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7554f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing nodes: 100%|██████████| 18281/18281 [16:52<00:00, 18.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the HPO ontology from the specified URL\n",
    "url = '../../hp.obo'  \n",
    "graph = obonet.read_obo(url)\n",
    "feature_dimension = 2048\n",
    "\n",
    "# Process each node in the graph to compute and store its embedding\n",
    "for node in tqdm(graph.nodes(), desc=\"Processing nodes\"):\n",
    "    try:\n",
    "        # Compute the embedding for the node\n",
    "        embedding = get_average_embedding(Ontology.get_hpo_object(node).name)\n",
    "        # Store the embedding in the node's features\n",
    "        graph.nodes[node]['feature'] = embedding\n",
    "    except ValueError as e:\n",
    "        # If NaN is detected, raise an error and terminate the program\n",
    "        print(f\"Error processing node {node}: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592cba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/HPO2SUM/github_project/Git_validation/PSD_HPOEncoder.py:76: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  dgl_graph.ndata['feat'] = torch.tensor(features, dtype=torch.float32)\n",
      "/root/anaconda3/envs/HT2VEC/lib/python3.8/site-packages/dgl/backend/pytorch/tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.250472068786621\n",
      "Epoch 10, Loss: 3.58121395111084\n",
      "Epoch 20, Loss: 3.309152364730835\n",
      "Epoch 30, Loss: 3.289189577102661\n",
      "Epoch 40, Loss: 3.1876633167266846\n",
      "Epoch 50, Loss: 3.1779816150665283\n",
      "Epoch 60, Loss: 3.1386053562164307\n",
      "Epoch 70, Loss: 3.1241912841796875\n",
      "Epoch 80, Loss: 3.100999355316162\n",
      "Epoch 90, Loss: 3.0129268169403076\n",
      "Epoch 100, Loss: 2.9341485500335693\n",
      "Epoch 110, Loss: 2.9474194049835205\n",
      "Epoch 120, Loss: 2.858182907104492\n",
      "Epoch 130, Loss: 2.8204548358917236\n",
      "Epoch 140, Loss: 2.7541074752807617\n",
      "Epoch 150, Loss: 2.611929178237915\n",
      "Epoch 160, Loss: 2.6177871227264404\n",
      "Epoch 170, Loss: 2.5599496364593506\n",
      "Epoch 180, Loss: 2.5176162719726562\n",
      "Epoch 190, Loss: 2.478886365890503\n",
      "Epoch 200, Loss: 2.4200682640075684\n",
      "Epoch 210, Loss: 2.3500373363494873\n",
      "Epoch 220, Loss: 2.31904673576355\n",
      "Epoch 230, Loss: 2.2613582611083984\n",
      "Epoch 240, Loss: 2.2600603103637695\n",
      "Epoch 250, Loss: 2.185352087020874\n",
      "Epoch 260, Loss: 2.143479347229004\n"
     ]
    }
   ],
   "source": [
    "dgl_graph = nx_to_dgl(graph)\n",
    "feature_dimension = 2048\n",
    "in_feats = feature_dimension\n",
    "h_feats = 256\n",
    "out_feats = feature_dimension\n",
    "\n",
    "# DGL graph does not implement the API for GPU, so we use CPU for computation\n",
    "device = torch.device(\"cpu\")\n",
    "model = GCN(in_feats, h_feats, out_feats).to(device)\n",
    "\n",
    "# train_model(model, dgl_graph, epochs=50, lr=0.001, node_mask_percentage=0.2, edge_mask_percentage=0.2)\n",
    "\n",
    "train_model(model, dgl_graph, epochs=500, lr=0.001, node_mask_percentage=0.2, edge_mask_percentage=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs, latent = model(dgl_graph, dgl_graph.ndata['feat'])\n",
    "node_embedding_dict = {node_id: latent[idx].numpy() for idx, node_id in enumerate(list(graph.nodes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./node_embedding_dict_test.plk', 'wb') as f:\n",
    "    pickle.dump(node_embedding_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215c9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python HT2VEC",
   "language": "python",
   "name": "ht2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
