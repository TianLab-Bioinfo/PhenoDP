{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pyhpo import Ontology\n",
    "\n",
    "from phenodp import PhenoDP_Initial\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate disease dict...\n",
      "related hpo num: 9216\n",
      "generate disease ic dict... \n",
      "calculating hp weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPO Processing: 100%|██████████| 655/655 [1:07:27<00:00,  6.18s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:08:16<00:00,  6.25s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:04<00:00,  6.33s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:12<00:00,  6.34s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:24<00:00,  6.36s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:26<00:00,  6.36s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:35<00:00,  6.38s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:39<00:00,  6.38s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:52<00:00,  6.40s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:09:58<00:00,  6.41s/it]\n",
      "HPO Processing:  99%|█████████▉| 648/655 [1:09:58<01:07,  9.60s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:00<00:00,  6.41s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:08<00:00,  6.43s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:12<00:00,  6.43s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:13<00:00,  6.43s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:21<00:00,  6.45s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:32<00:00,  6.46s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:37<00:00,  6.47s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:10:51<00:00,  6.49s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:11:05<00:00,  6.51s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:11:14<00:00,  6.53s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:11:37<00:00,  6.56s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:11:43<00:00,  6.57s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:11:49<00:00,  6.58s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:12:10<00:00,  6.61s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:12:17<00:00,  6.62s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:12:18<00:00,  6.62s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:12:20<00:00,  6.63s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:13:01<00:00,  6.69s/it]\n",
      "HPO Processing: 100%|██████████| 655/655 [1:13:10<00:00,  6.70s/it]\n"
     ]
    }
   ],
   "source": [
    "ontology = Ontology(data_folder='../data/hpo-2025-05-06')\n",
    "\n",
    "pre_model = PhenoDP_Initial(ontology)\n",
    "hpo_len = len(pre_model.hpo_list)\n",
    "\n",
    "num_groups = 30  # Number of groups to divide the task into\n",
    "max_workers = 30  # Number of threads/processes to use\n",
    "\n",
    "group_size = hpo_len // num_groups\n",
    "\n",
    "def run_initial_sim(start, end):\n",
    "    return pre_model.initial_sim(start=start, end=end)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(run_initial_sim, i * group_size, (i + 1) * group_size) for i in range(num_groups)]\n",
    "    results = [future.result() for future in futures]\n",
    "\n",
    "hp2d_sim_dict = []\n",
    "processed_list = []\n",
    "\n",
    "for result in results:\n",
    "    hp2d_sim_dict.extend(result[0])  # Merge dictionaries\n",
    "    processed_list.extend(result[1])  # Extend lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df = pd.DataFrame(hp2d_sim_dict, index=processed_list, columns=[str(t) for t in pre_model.disease_list])\n",
    "JC_sim_dict = df.to_dict(orient='index')\n",
    "\n",
    "with open('../data/JC_sim_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(JC_sim_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenodp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
